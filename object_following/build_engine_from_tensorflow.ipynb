{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "static-remains",
   "metadata": {},
   "source": [
    "# Convert SSD Mobilenet from TensorFlow to TensorRT\n",
    "\n",
    "TensorFlow has a large selection of pre-trained SSD models in its [object detection model zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md).\n",
    "\n",
    "This tutorial shows how to convert them to UFF and then to TensorRT.\n",
    "\n",
    "**NOTE**: NVIDIA has deprecated the Caffe Parser and UFF Parser in TensorRT 7.0. It is expected that converting to ONNX will be required in the future, but for now we will convert to UFF.  \n",
    "https://docs.nvidia.com/deeplearning/tensorrt/release-notes/tensorrt-7.html\n",
    "\n",
    "This notebook is based on  \n",
    "https://github.com/jkjung-avt/tensorrt_demos/blob/9dd56b3b8d841dcfc2e5d1868f4bd785a50cbe98/ssd/build_engine.py  \n",
    "which is released under the MIT License.\n",
    "\n",
    "Copyright (c) 2019 JK Jung  \n",
    "https://github.com/jkjung-avt/tensorrt_demos/blob/9dd56b3b8d841dcfc2e5d1868f4bd785a50cbe98/LICENSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-aquarium",
   "metadata": {},
   "source": [
    "## Downgrading TensorFlow to  make it compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "informed-bacteria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "E: Unable to locate package tensorflow\n"
     ]
    }
   ],
   "source": [
    "!apt install --upgrade tensorflow=1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "concrete-settle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.2\n"
     ]
    }
   ],
   "source": [
    "import ctypes\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import uff\n",
    "import tensorrt as trt\n",
    "import graphsurgeon as gs\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intellectual-establishment",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "funny-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_addv2(graph):\n",
    "    \"\"\"Replace all 'AddV2' in the graph with 'Add'.\n",
    "\n",
    "    'AddV2' is not supported by UFF parser.\n",
    "\n",
    "    Reference:\n",
    "    1. https://github.com/jkjung-avt/tensorrt_demos/issues/113#issuecomment-629900809\n",
    "    \"\"\"\n",
    "    for node in graph.find_nodes_by_op('AddV2'):\n",
    "        gs.update_node(node, op='Add')\n",
    "    return graph\n",
    "\n",
    "\n",
    "def replace_fusedbnv3(graph):\n",
    "    \"\"\"Replace all 'FusedBatchNormV3' in the graph with 'FusedBatchNorm'.\n",
    "\n",
    "    'FusedBatchNormV3' is not supported by UFF parser.\n",
    "\n",
    "    Reference:\n",
    "    1. https://devtalk.nvidia.com/default/topic/1066445/tensorrt/tensorrt-6-0-1-tensorflow-1-14-no-conversion-function-registered-for-layer-fusedbatchnormv3-yet/post/5403567/#5403567\n",
    "    2. https://github.com/jkjung-avt/tensorrt_demos/issues/76#issuecomment-607879831\n",
    "    \"\"\"\n",
    "    for node in graph.find_nodes_by_op('FusedBatchNormV3'):\n",
    "        gs.update_node(node, op='FusedBatchNorm')\n",
    "    return graph\n",
    "\n",
    "\n",
    "def add_anchor_input(graph):\n",
    "    \"\"\"Add the missing const input for the GridAnchor node.\n",
    "\n",
    "    Reference:\n",
    "    1. https://www.minds.ai/post/deploying-ssd-mobilenet-v2-on-the-nvidia-jetson-and-nano-platforms\n",
    "    \"\"\"\n",
    "    data = np.array([1, 1], dtype=np.float32)\n",
    "    anchor_input = gs.create_node('AnchorInput', 'Const', value=data)\n",
    "    graph.append(anchor_input)\n",
    "    graph.find_nodes_by_op('GridAnchor_TRT')[0].input.insert(0, 'AnchorInput')\n",
    "    return graph\n",
    "\n",
    "def add_plugin(graph, num_classes, min_size, max_size, input_order):\n",
    "    \"\"\"add_plugin\n",
    "\n",
    "    Reference:\n",
    "    1. https://github.com/AastaNV/TRT_object_detection/blob/master/config/model_ssd_mobilenet_v1_coco_2018_01_28.py\n",
    "    2. https://github.com/AastaNV/TRT_object_detection/blob/master/config/model_ssd_mobilenet_v2_coco_2018_03_29.py\n",
    "    3. https://devtalk.nvidia.com/default/topic/1050465/jetson-nano/how-to-write-config-py-for-converting-ssd-mobilenetv2-to-uff-format/post/5333033/#5333033\n",
    "    \"\"\"\n",
    "    numClasses, minSize, maxSize, inputOrder = num_classes, min_size, max_size, input_order\n",
    "\n",
    "    all_assert_nodes = graph.find_nodes_by_op('Assert')\n",
    "    graph.remove(all_assert_nodes, remove_exclusive_dependencies=True)\n",
    "\n",
    "    all_identity_nodes = graph.find_nodes_by_op('Identity')\n",
    "    graph.forward_inputs(all_identity_nodes)\n",
    "\n",
    "    Input = gs.create_plugin_node(\n",
    "        name='Input',\n",
    "        op='Placeholder',\n",
    "        shape=(1,) + (3, 300, 300)\n",
    "    )\n",
    "\n",
    "    PriorBox = gs.create_plugin_node(\n",
    "        name='MultipleGridAnchorGenerator',\n",
    "        op='GridAnchor_TRT',\n",
    "        minSize=minSize,  # was 0.2\n",
    "        maxSize=maxSize,  # was 0.95\n",
    "        aspectRatios=[1.0, 2.0, 0.5, 3.0, 0.33],\n",
    "        variance=[0.1, 0.1, 0.2, 0.2],\n",
    "        featureMapShapes=[19, 10, 5, 3, 2, 1],\n",
    "        numLayers=6\n",
    "    )\n",
    "\n",
    "    NMS = gs.create_plugin_node(\n",
    "        name='NMS',\n",
    "        op='NMS_TRT',\n",
    "        shareLocation=1,\n",
    "        varianceEncodedInTarget=0,\n",
    "        backgroundLabelId=0,\n",
    "        confidenceThreshold=0.3,  # was 1e-8\n",
    "        nmsThreshold=0.6,\n",
    "        topK=100,\n",
    "        keepTopK=100,\n",
    "        numClasses=numClasses,  # was 91\n",
    "        inputOrder=inputOrder,\n",
    "        confSigmoid=1,\n",
    "        isNormalized=1\n",
    "    )\n",
    "\n",
    "    concat_priorbox = gs.create_node(\n",
    "        'concat_priorbox',\n",
    "        op='ConcatV2',\n",
    "        axis=2\n",
    "    )\n",
    "\n",
    "    if trt.__version__[0] >= '7':\n",
    "        concat_box_loc = gs.create_plugin_node(\n",
    "            'concat_box_loc',\n",
    "            op='FlattenConcat_TRT',\n",
    "            axis=1,\n",
    "            ignoreBatch=0\n",
    "        )\n",
    "        concat_box_conf = gs.create_plugin_node(\n",
    "            'concat_box_conf',\n",
    "            op='FlattenConcat_TRT',\n",
    "            axis=1,\n",
    "            ignoreBatch=0\n",
    "        )\n",
    "    else:\n",
    "        concat_box_loc = gs.create_plugin_node(\n",
    "            'concat_box_loc',\n",
    "            op='FlattenConcat_TRT'\n",
    "        )\n",
    "        concat_box_conf = gs.create_plugin_node(\n",
    "            'concat_box_conf',\n",
    "            op='FlattenConcat_TRT'\n",
    "        )\n",
    "\n",
    "    namespace_for_removal = [\n",
    "        'ToFloat',\n",
    "        'image_tensor',\n",
    "        'Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3',\n",
    "    ]\n",
    "    namespace_plugin_map = {\n",
    "        'MultipleGridAnchorGenerator': PriorBox,\n",
    "        'Postprocessor': NMS,\n",
    "        'Preprocessor': Input,\n",
    "        'ToFloat': Input,\n",
    "        'Cast': Input,  # added for models trained with tf 1.15+\n",
    "        'image_tensor': Input,\n",
    "        'MultipleGridAnchorGenerator/Concatenate': concat_priorbox,  # for 'ssd_mobilenet_v1_coco'\n",
    "        'Concatenate': concat_priorbox,  # for other models\n",
    "        'concat': concat_box_loc,\n",
    "        'concat_1': concat_box_conf\n",
    "    }\n",
    "\n",
    "    graph.remove(graph.find_nodes_by_path(['Preprocessor/map/TensorArrayStack_1/TensorArrayGatherV3']), remove_exclusive_dependencies=False)  # for 'ssd_inception_v2_coco'\n",
    "\n",
    "    graph.collapse_namespaces(namespace_plugin_map)\n",
    "    graph = replace_addv2(graph)\n",
    "    graph = replace_fusedbnv3(graph)\n",
    "\n",
    "    if 'image_tensor:0' in graph.find_nodes_by_name('Input')[0].input:\n",
    "        graph.find_nodes_by_name('Input')[0].input.remove('image_tensor:0')\n",
    "    if 'Input' in graph.find_nodes_by_name('NMS')[0].input:\n",
    "        graph.find_nodes_by_name('NMS')[0].input.remove('Input')\n",
    "    # Remove the Squeeze to avoid \"Assertion 'isPlugin(layerName)' failed\"\n",
    "    graph.forward_inputs(graph.find_node_inputs_by_name(graph.graph_outputs[0], 'Squeeze'))\n",
    "    if 'anchors' in [node.name for node in graph.graph_outputs]:\n",
    "        graph.remove('anchors', remove_exclusive_dependencies=False)\n",
    "    if len(graph.find_nodes_by_op('GridAnchor_TRT')[0].input) < 1:\n",
    "        graph = add_anchor_input(graph)\n",
    "    if 'NMS' not in [node.name for node in graph.graph_outputs]:\n",
    "        graph.remove(graph.graph_outputs, remove_exclusive_dependencies=False)\n",
    "        if 'NMS' not in [node.name for node in graph.graph_outputs]:\n",
    "            # We expect 'NMS' to be one of the outputs\n",
    "            raise RuntimeError('bad graph_outputs')\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opponent-garlic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize\n",
    "if trt.__version__[0] < '7':\n",
    "    try:\n",
    "        from jnmouse.ssd_tensorrt import load_flattenconcat_plugin\n",
    "        load_flattenconcat_plugin()\n",
    "    except:\n",
    "        import ctypes\n",
    "        import os\n",
    "        from pathlib import Path\n",
    "        import subprocess\n",
    "        import sys\n",
    "        command1 = [\"cp\", \"-r\", \"/usr/src/tensorrt/samples/python/uff_ssd/\", \".\"], Path().resolve() \n",
    "        command2 = [\"mkdir\", \"-p\", \"uff_ssd/build\"], Path().resolve()\n",
    "        command3 = [\"cmake\", \"..\"], \"{}/uff_ssd/build\".format(Path().resolve())\n",
    "        command4 = [\"make\"], \"{}/uff_ssd/build\".format(Path().resolve())\n",
    "        command5 = [\"chmod\", \"-x\", \"libflattenconcat.so\"], \"{}/uff_ssd/build\".format(Path().resolve())\n",
    "        command6 = [\"cp\", \"libflattenconcat.so\", \"../../libflattenconcat.so.{}\".format(trt.__version__[0])], \"{}/uff_ssd/build\".format(Path().resolve())\n",
    "        for commands in (command1, command2, command3, command4, command5, command6):\n",
    "            command, cwd = commands\n",
    "            print(command)\n",
    "            res = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, cwd=cwd)\n",
    "            print(res.stdout.decode(\"utf8\"))\n",
    "            if res.stderr: print(res.stderr.decode(\"utf8\"))\n",
    "\n",
    "        LIB_FILE = os.path.abspath(os.path.join(Path().resolve(), 'libflattenconcat.so.{}'.format(trt.__version__[0])))\n",
    "        ctypes.CDLL(LIB_FILE)\n",
    "\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "\n",
    "# load plugins\n",
    "trt.init_libnvinfer_plugins(TRT_LOGGER, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-nashville",
   "metadata": {},
   "source": [
    "## Download the pre-trained model and configure parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-girlfriend",
   "metadata": {},
   "source": [
    "Download the pre-trained ssd_mobilenet_v2_coco model.  \n",
    "http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "united-copyright",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-11 11:23:52--  http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... ^C\n"
     ]
    }
   ],
   "source": [
    "# SSD MobileNetV2 COCO\n",
    "!wget -O - http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz | tar zxvf -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "southeast-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSD MobileNetV2 COCO\n",
    "tensorflow_model_path = \"SSD-Mobilenet-V2-tf/frozen_inference_graph.pb\"\n",
    "uff_model_path = \"ssd_mobilenet_v2_coco.uff\"\n",
    "trt_engine_path = \"ssd_mobilenet_v2_coco_trt{}_t210.engine\".format(trt.__version__[0])\n",
    "num_classes = 91\n",
    "min_size = 0.2\n",
    "max_size = 0.95\n",
    "input_order = [1, 0, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broad-trauma",
   "metadata": {},
   "source": [
    "## Convert the pre-trained model to the TensorRT engine file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-production",
   "metadata": {},
   "source": [
    "NOTE: If you get `TypeError: Cannot convert value 0 to a TensorFlow DType.` on part 1,  \n",
    "`/usr/lib/python3.6/dist-packages/graphsurgeon/node_manipulation.py` sould be updated.  \n",
    "https://github.com/AastaNV/TRT_object_detection#update-graphsurgeon-converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "joint-international",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build .uff file\n",
      "NOTE: UFF has been tested with TensorFlow 1.15.0.\n",
      "WARNING: The version of TensorFlow installed on this system is not guaranteed to work with UFF.\n",
      "UFF Version 0.6.9\n",
      "=== Automatically deduced input nodes ===\n",
      "[name: \"Input\"\n",
      "op: \"Placeholder\"\n",
      "attr {\n",
      "  key: \"dtype\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"shape\"\n",
      "  value {\n",
      "    shape {\n",
      "      dim {\n",
      "        size: 1\n",
      "      }\n",
      "      dim {\n",
      "        size: 3\n",
      "      }\n",
      "      dim {\n",
      "        size: 300\n",
      "      }\n",
      "      dim {\n",
      "        size: 300\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "]\n",
      "=========================================\n",
      "\n",
      "Using output node NMS\n",
      "Converting to UFF graph\n",
      "Warning: No conversion function registered for layer: NMS_TRT yet.\n",
      "Converting NMS as custom op: NMS_TRT\n",
      "WARNING:tensorflow:From /usr/lib/python3.6/dist-packages/uff/converters/tensorflow/converter.py:226: The name tf.AttrValue is deprecated. Please use tf.compat.v1.AttrValue instead.\n",
      "\n",
      "Warning: No conversion function registered for layer: GridAnchor_TRT yet.\n",
      "Converting MultipleGridAnchorGenerator as custom op: GridAnchor_TRT\n",
      "Warning: No conversion function registered for layer: FlattenConcat_TRT yet.\n",
      "Converting concat_box_loc as custom op: FlattenConcat_TRT\n",
      "Warning: No conversion function registered for layer: FlattenConcat_TRT yet.\n",
      "Converting concat_box_conf as custom op: FlattenConcat_TRT\n",
      "DEBUG [/usr/lib/python3.6/dist-packages/uff/converters/tensorflow/converter.py:143] Marking ['NMS'] as outputs\n",
      "No. nodes: 1094\n",
      "UFF Output written to ssd_mobilenet_v2_coco.uff\n",
      "UFF Text Output written to ssd_mobilenet_v2_coco.pbtxt\n",
      "built .uff file successfully\n"
     ]
    }
   ],
   "source": [
    "# convert the model into TensorRT engine\n",
    "# part 1: compile the UFF file\n",
    "print(\"build .uff file\")\n",
    "dynamic_graph = add_plugin(\n",
    "    gs.DynamicGraph(tensorflow_model_path),\n",
    "    num_classes, min_size, max_size, input_order)\n",
    "\n",
    "_ = uff.from_tensorflow(\n",
    "    dynamic_graph.as_graph_def(),\n",
    "    output_nodes=['NMS'],\n",
    "    output_filename=uff_model_path,\n",
    "    text=True,\n",
    "    debug_mode=False)\n",
    "\n",
    "print(\"built .uff file successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "macro-pulse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build .engine file\n",
      "parsing model\n",
      "building engine\n",
      "saving engine\n",
      "built .engine file successfully\n",
      "Finished converting the pre-trained model into TensorRT engine successfully\n"
     ]
    }
   ],
   "source": [
    "# covert the model into TensorRT engine\n",
    "# part 2: compile the .engine/.bin file\n",
    "print(\"build .engine file\")\n",
    "with trt.Builder(TRT_LOGGER) as builder, builder.create_network() as network, trt.UffParser() as parser:\n",
    "\n",
    "    builder.max_workspace_size = 1 << 28\n",
    "    builder.max_batch_size = 1\n",
    "    builder.fp16_mode = True\n",
    "\n",
    "    parser.register_input('Input', (3, 300, 300))\n",
    "    parser.register_output('MarkOutput_0')\n",
    "\n",
    "    print(\"parsing model\")\n",
    "    parser.parse(uff_model_path, network)\n",
    "\n",
    "    print(\"building engine\")\n",
    "    with builder.build_cuda_engine(network) as engine:\n",
    "        print(\"saving engine\")\n",
    "        with open(trt_engine_path, 'wb') as f:\n",
    "            f.write(engine.serialize())\n",
    "\n",
    "print(\"built .engine file successfully\")\n",
    "print(\"Finished converting the pre-trained model into TensorRT engine successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-egyptian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
